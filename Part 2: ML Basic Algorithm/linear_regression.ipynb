{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9271edcf",
   "metadata": {},
   "source": [
    "## Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cb2b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n, k, p = 100, 8, 3\n",
    "X = np.random.randn(n, k) # 100*8\n",
    "Y = np.random.rand(n, p) # 100*3\n",
    "\n",
    "W = np.random.randn(k, p) # 8*3\n",
    "\n",
    "alpha = 1e-3\n",
    "max_itr = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3814a9",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e3a5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W):\n",
    "    \"\"\"\n",
    "    X: (n, k)\n",
    "    W: (k, p)\n",
    "    return: Y_hat (n, p)\n",
    "    \"\"\"\n",
    "    return np.matmul(X, W) # 100*8 and 8*3 return 100*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74e4212",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13fe8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Squared error loss\n",
    "    \"\"\"\n",
    "    E = Y_hat-Y # error 100*3\n",
    "    loss_value = np.sum(E**2) # mse \n",
    "    return E, loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5718f5",
   "metadata": {},
   "source": [
    "## Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7ac476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, E):\n",
    "    \"\"\"\n",
    "    Gradient of loss w.r.t W\n",
    "    \"\"\"\n",
    "    grad_W = 2*np.matmul(X.T, E) # X.T: 8*100 E: 100*3 \n",
    "    # X.T(Y_hat_Y) is the gradient of W in loss function\n",
    "    return grad_W # 8*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22a851",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e011b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, Y, W, alpha, max_itr):\n",
    "    for i in range(max_itr):\n",
    "        # Forward\n",
    "        Y_hat = forward(X, W)\n",
    "\n",
    "        # Loss\n",
    "        E, L = loss(Y_hat, Y) # error, mse\n",
    "\n",
    "        # Backward\n",
    "        grad_W = backward(X, E)\n",
    "\n",
    "        # Update\n",
    "        W-=alpha*grad_W\n",
    "\n",
    "        if i%10==0:\n",
    "            print(f\"iter{i}, loss={L:.4f}, W={W}\")\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99f2dbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0, loss=2002.4465, W=[[-0.15518939 -0.76836147 -0.67083583]\n",
      " [ 0.4213657   0.05484097 -0.73123126]\n",
      " [-0.11710926 -0.60637151  0.52278888]\n",
      " [-0.30375326 -0.83198875 -0.3513228 ]\n",
      " [-1.16318125  1.10128405  0.21414826]\n",
      " [-1.0669386   0.38869412  1.06045986]\n",
      " [-0.02356459  1.50808969 -0.86481501]\n",
      " [-0.80932912 -0.28919898 -0.45939361]]\n",
      "iter10, loss=127.3274, W=[[-0.01208256 -0.30009683 -0.15877269]\n",
      " [ 0.015028    0.18403768  0.0148603 ]\n",
      " [-0.06584644 -0.27150018  0.04081779]\n",
      " [-0.19053263 -0.0355051  -0.15030641]\n",
      " [-0.21685464  0.01012626 -0.00472788]\n",
      " [-0.20489613  0.23934289  0.12618012]\n",
      " [-0.02607017  0.1660768  -0.13726242]\n",
      " [-0.18540842 -0.02509796 -0.11921193]]\n",
      "iter20, loss=96.3321, W=[[-0.03044611 -0.10909742 -0.09124375]\n",
      " [ 0.03758879  0.11098529  0.05428528]\n",
      " [-0.0712661  -0.15716133 -0.08252302]\n",
      " [-0.13849312  0.01692829 -0.08493214]\n",
      " [-0.09211019 -0.08304039 -0.03831792]\n",
      " [-0.04338235  0.11696363  0.02305437]\n",
      " [-0.00238781  0.00783244 -0.06761354]\n",
      " [-0.09972671 -0.04271474 -0.09546783]]\n",
      "iter30, loss=94.2714, W=[[-0.04697089 -0.04779724 -0.08104447]\n",
      " [ 0.05053096  0.08110224  0.05957623]\n",
      " [-0.08638926 -0.1086103  -0.10869457]\n",
      " [-0.12509978  0.01391612 -0.07034268]\n",
      " [-0.07368781 -0.09535571 -0.04433029]\n",
      " [-0.00537451  0.06641347  0.01333717]\n",
      " [ 0.01074225 -0.02956067 -0.05784497]\n",
      " [-0.08393742 -0.05492384 -0.09381973]]\n",
      "iter40, loss=94.0382, W=[[-0.05434792 -0.02764324 -0.08003051]\n",
      " [ 0.05547182  0.07013651  0.06101057]\n",
      " [-0.09432546 -0.08923075 -0.11462204]\n",
      " [-0.12134769  0.00996729 -0.06713482]\n",
      " [-0.07047271 -0.0982086  -0.04527178]\n",
      " [ 0.00535651  0.04766242  0.01328333]\n",
      " [ 0.0161108  -0.0420062  -0.05572524]\n",
      " [-0.080346   -0.05958112 -0.09348748]]\n",
      "iter50, loss=94.0082, W=[[-0.05722379 -0.02072924 -0.08019495]\n",
      " [ 0.0573013   0.06613279  0.06149527]\n",
      " [-0.09761642 -0.08182115 -0.11613929]\n",
      " [-0.12016185  0.00807823 -0.0663894 ]\n",
      " [-0.06978096 -0.09910528 -0.0453819 ]\n",
      " [ 0.00880382  0.0408328   0.01373816]\n",
      " [ 0.0181467  -0.04649659 -0.05510644]\n",
      " [-0.0793483  -0.06128611 -0.09333863]]\n",
      "iter60, loss=94.0042, W=[[-0.05829894 -0.01828698 -0.08035889]\n",
      " [ 0.05797389  0.06466975  0.06166843]\n",
      " [-0.09888057 -0.07905038 -0.11657934]\n",
      " [-0.11975609  0.0073109  -0.06620017]\n",
      " [-0.06959688 -0.09941678 -0.04538141]\n",
      " [ 0.00999296  0.03834742  0.01397377]\n",
      " [ 0.01890094 -0.04813851 -0.05489979]\n",
      " [-0.07902931 -0.06190973 -0.09327452]]\n",
      "iter70, loss=94.0036, W=[[-0.05869512 -0.01740985 -0.08043866]\n",
      " [ 0.05822042  0.06413487  0.06173127]\n",
      " [-0.09935222 -0.07802574 -0.11671995]\n",
      " [-0.11961167  0.0070166  -0.06614699]\n",
      " [-0.06953955 -0.09952839 -0.04537437]\n",
      " [ 0.01041711  0.03744145  0.01407064]\n",
      " [ 0.01917811 -0.04873966 -0.05482703]\n",
      " [-0.07891934 -0.06213794 -0.09324919]]\n",
      "iter80, loss=94.0036, W=[[-0.05884036 -0.01709204 -0.08047157]\n",
      " [ 0.05831065  0.0639393   0.06175418]\n",
      " [-0.09952614 -0.07764893 -0.11676776]\n",
      " [-0.11955941  0.0069065  -0.06613059]\n",
      " [-0.06952006 -0.09956882 -0.04537065]\n",
      " [ 0.01057061  0.03711076  0.01410779]\n",
      " [ 0.01927966 -0.04895967 -0.05480087]\n",
      " [-0.07888011 -0.06222143 -0.09323963]]\n",
      "iter90, loss=94.0036, W=[[-0.05889351 -0.01697637 -0.08048431]\n",
      " [ 0.05834366  0.06386779  0.06176255]\n",
      " [-0.09958996 -0.07751075 -0.1167846 ]\n",
      " [-0.11954036  0.00686578 -0.06612516]\n",
      " [-0.06951314 -0.09958354 -0.04536909]\n",
      " [ 0.01062651  0.03698995  0.01412166]\n",
      " [ 0.01931682 -0.04904016 -0.05479138]\n",
      " [-0.0788659  -0.06225198 -0.09323608]]\n",
      "iter100, loss=94.0036, W=[[-0.05891295 -0.01693417 -0.0804891 ]\n",
      " [ 0.05835574  0.06384163  0.06176561]\n",
      " [-0.09961333 -0.07746015 -0.11679064]\n",
      " [-0.11953341  0.0068508  -0.06612329]\n",
      " [-0.06951065 -0.09958891 -0.0453685 ]\n",
      " [ 0.01064691  0.0369458   0.01412678]\n",
      " [ 0.01933042 -0.0490696  -0.05478792]\n",
      " [-0.07886073 -0.06226315 -0.09323478]]\n",
      "iter110, loss=94.0036, W=[[-0.05892006 -0.01691875 -0.08049088]\n",
      " [ 0.05836015  0.06383207  0.06176673]\n",
      " [-0.09962188 -0.07744164 -0.11679283]\n",
      " [-0.11953087  0.00684531 -0.06612263]\n",
      " [-0.06950974 -0.09959087 -0.04536827]\n",
      " [ 0.01065436  0.03692965  0.01412866]\n",
      " [ 0.01933539 -0.04908037 -0.05478666]\n",
      " [-0.07885884 -0.06226723 -0.0932343 ]]\n",
      "iter120, loss=94.0036, W=[[-0.05892266 -0.01691312 -0.08049153]\n",
      " [ 0.05836177  0.06382858  0.06176714]\n",
      " [-0.09962501 -0.07743486 -0.11679363]\n",
      " [-0.11952994  0.0068433  -0.06612239]\n",
      " [-0.06950941 -0.09959159 -0.04536819]\n",
      " [ 0.01065709  0.03692375  0.01412935]\n",
      " [ 0.01933721 -0.0490843  -0.0547862 ]\n",
      " [-0.07885815 -0.06226873 -0.09323413]]\n",
      "iter130, loss=94.0036, W=[[-0.05892361 -0.01691106 -0.08049177]\n",
      " [ 0.05836236  0.0638273   0.06176729]\n",
      " [-0.09962615 -0.07743238 -0.11679392]\n",
      " [-0.1195296   0.00684257 -0.0661223 ]\n",
      " [-0.06950929 -0.09959185 -0.04536816]\n",
      " [ 0.01065808  0.03692159  0.0141296 ]\n",
      " [ 0.01933787 -0.04908574 -0.05478603]\n",
      " [-0.0788579  -0.06226927 -0.09323406]]\n",
      "iter140, loss=94.0036, W=[[-0.05892395 -0.01691031 -0.08049186]\n",
      " [ 0.05836257  0.06382683  0.06176735]\n",
      " [-0.09962657 -0.07743148 -0.11679402]\n",
      " [-0.11952947  0.0068423  -0.06612227]\n",
      " [-0.06950924 -0.09959194 -0.04536815]\n",
      " [ 0.01065845  0.03692081  0.01412969]\n",
      " [ 0.01933812 -0.04908627 -0.05478597]\n",
      " [-0.07885781 -0.06226947 -0.09323404]]\n",
      "iter150, loss=94.0036, W=[[-0.05892408 -0.01691004 -0.08049189]\n",
      " [ 0.05836265  0.06382666  0.06176737]\n",
      " [-0.09962672 -0.07743115 -0.11679406]\n",
      " [-0.11952943  0.0068422  -0.06612226]\n",
      " [-0.06950923 -0.09959198 -0.04536814]\n",
      " [ 0.01065858  0.03692052  0.01412972]\n",
      " [ 0.0193382  -0.04908646 -0.05478595]\n",
      " [-0.07885777 -0.06226955 -0.09323403]]\n",
      "iter160, loss=94.0036, W=[[-0.05892413 -0.01690993 -0.0804919 ]\n",
      " [ 0.05836268  0.0638266   0.06176737]\n",
      " [-0.09962678 -0.07743103 -0.11679408]\n",
      " [-0.11952941  0.00684216 -0.06612225]\n",
      " [-0.06950922 -0.09959199 -0.04536814]\n",
      " [ 0.01065863  0.03692041  0.01412974]\n",
      " [ 0.01933824 -0.04908653 -0.05478594]\n",
      " [-0.07885776 -0.06226957 -0.09323403]]\n",
      "iter170, loss=94.0036, W=[[-0.05892414 -0.0169099  -0.08049191]\n",
      " [ 0.05836269  0.06382657  0.06176738]\n",
      " [-0.0996268  -0.07743098 -0.11679408]\n",
      " [-0.1195294   0.00684215 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065865  0.03692037  0.01412974]\n",
      " [ 0.01933825 -0.04908656 -0.05478594]\n",
      " [-0.07885776 -0.06226958 -0.09323403]]\n",
      "iter180, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.05836269  0.06382657  0.06176738]\n",
      " [-0.09962681 -0.07743097 -0.11679408]\n",
      " [-0.1195294   0.00684215 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065865  0.03692036  0.01412974]\n",
      " [ 0.01933825 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter190, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933825 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter200, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter210, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter220, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter230, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter240, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter250, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter260, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter270, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter280, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter290, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter300, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter310, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter320, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter330, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter340, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter350, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter360, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter370, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter380, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter390, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter400, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter410, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter420, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter430, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter440, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter450, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter460, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter470, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter480, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter490, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter500, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter510, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter520, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter530, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter540, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter550, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter560, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter570, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter580, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter590, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter600, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter610, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter620, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter630, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter640, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter650, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter660, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter670, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter680, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter690, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter700, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter710, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter720, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter730, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter740, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter750, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter760, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter770, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter780, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter790, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter800, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter810, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter820, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter830, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter840, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter850, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter860, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter870, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter880, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter890, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter900, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter910, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter920, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter930, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter940, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter950, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter960, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter970, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter980, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n",
      "iter990, loss=94.0036, W=[[-0.05892415 -0.01690988 -0.08049191]\n",
      " [ 0.0583627   0.06382656  0.06176738]\n",
      " [-0.09962681 -0.07743096 -0.11679409]\n",
      " [-0.1195294   0.00684214 -0.06612225]\n",
      " [-0.06950922 -0.099592   -0.04536814]\n",
      " [ 0.01065866  0.03692035  0.01412974]\n",
      " [ 0.01933826 -0.04908657 -0.05478594]\n",
      " [-0.07885775 -0.06226959 -0.09323402]]\n"
     ]
    }
   ],
   "source": [
    "W_final = fit(X, Y, W, alpha, max_itr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prod_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
