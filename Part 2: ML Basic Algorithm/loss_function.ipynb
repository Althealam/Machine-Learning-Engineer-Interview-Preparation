{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b652257a",
   "metadata": {},
   "source": [
    "## Regression Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd1fe7",
   "metadata": {},
   "source": [
    "### 1. MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "82c36065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true_np = np.array([3.0, 5.0, 2.5])\n",
    "y_pred_np = np.array([2.5, 5.5, 2.0])\n",
    "\n",
    "def mse_loss(pred, target):\n",
    "    return np.mean((pred-target)**2)\n",
    "mse = mse_loss(y_pred_np, y_true_np)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "87f2027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: tensor(0.2500, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "y_true_t = torch.tensor([3.0, 5.0, 2.5])\n",
    "y_pred_t = torch.tensor([2.5, 5.5, 2.0], requires_grad=True)\n",
    "# requires_grad: 这个tensor参与梯度计算，需要在反向传播的时候计算他的梯度\n",
    "\n",
    "def mse_loss(pred, target):\n",
    "    return torch.mean((pred-target)**2)\n",
    "mse = mse_loss(y_pred_t, y_true_t)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faea552",
   "metadata": {},
   "source": [
    "### 2. MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b9bdf0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5\n"
     ]
    }
   ],
   "source": [
    "def mae_loss(pred, target):\n",
    "    return np.mean(np.abs(pred-target))\n",
    "\n",
    "mae = mae_loss(y_pred_np, y_true_np)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "27af240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: tensor(0.5000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def mae_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred-target))\n",
    "\n",
    "mae = mae_loss(y_pred_t, y_true_t)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422c907",
   "metadata": {},
   "source": [
    "### 3. Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9ed1130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huber loss: 0.125\n"
     ]
    }
   ],
   "source": [
    "def huber_loss(pred, target, delta=1.0):\n",
    "    diff = np.abs(pred-target)\n",
    "    loss = np.where(\n",
    "        diff<=delta, \n",
    "        0.5*diff**2, \n",
    "        delta*(diff-0.5*delta)\n",
    "    )\n",
    "    return np.mean(loss)\n",
    "huber_loss = huber_loss(y_pred_np, y_true_np)\n",
    "print(\"huber loss:\", huber_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8f993384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huber loss: tensor(0.1250, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def huber_loss(pred, target, delta=1.0):\n",
    "    diff = torch.abs(pred-target)\n",
    "    loss = torch.where(\n",
    "        diff<=delta, \n",
    "        0.5*diff**2, \n",
    "        delta*(diff-0.5*delta)\n",
    "    )\n",
    "    return loss.mean()\n",
    "huber_loss = huber_loss(y_pred_t, y_true_t)\n",
    "print(\"huber loss:\", huber_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0d0a7",
   "metadata": {},
   "source": [
    "### 4. RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6f2f7088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5\n"
     ]
    }
   ],
   "source": [
    "def rmse_loss(pred, target):\n",
    "    return np.sqrt(np.mean((pred-target)**2))\n",
    "rmse = rmse_loss(y_pred_np, y_true_np)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a2f5a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: tensor(0.5000, grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def rmse_loss(pred, target):\n",
    "    return torch.sqrt(torch.mean((pred-target)**2))\n",
    "rmse = rmse_loss(y_pred_t, y_true_t)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa6e3f",
   "metadata": {},
   "source": [
    "## Classification Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fb646",
   "metadata": {},
   "source": [
    "### 1. Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6bd32239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y_true_np = np.array([1, 0, 1])\n",
    "y_true_t = torch.tensor([1., 0., 1.])\n",
    "\n",
    "# logits\n",
    "logits_np = np.array([0.2, 0.6, 0.2])\n",
    "logits_t = torch.tensor([0.2, 0.6, 0.2], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3f71cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE Loss: 1.3779722793012823\n"
     ]
    }
   ],
   "source": [
    "def bce_loss(pred, target, eps=1e-4):\n",
    "    return -np.mean(target*np.log(pred+eps)+(1-target)*np.log(1-pred+eps))\n",
    "\n",
    "bce_loss = bce_loss(logits_np, y_true_np)\n",
    "print(\"BCE Loss:\", bce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "69d8f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE Loss: tensor(-1.3780, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def bce_loss(pred, target, eps=1e-4):\n",
    "    return torch.mean(target*torch.log(pred+eps)+(1-target)*torch.log(1-pred+eps))\n",
    "bce_loss = bce_loss(logits_t, y_true_t)\n",
    "print(\"BCE Loss:\", bce_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47acd18f",
   "metadata": {},
   "source": [
    "### 2. Categorical Cross-Entropy (multiclass, but have only one label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4bd20516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch=3, classes=4\n",
    "logits_np = np.array([\n",
    "    [2.0, 1.0, 0.1, -1.0],  # batch 1\n",
    "    [0.5, 2.5, 0.3, 0.1], # batch 2\n",
    "    [1.2, 0.2, 2.0, 0.5] # batch 3\n",
    "])\n",
    "\n",
    "labels_np = np.array([0, 1, 2])\n",
    "\n",
    "logits_t = torch.tensor([\n",
    "    [2.0, 1.0, 0.1, -1.0],\n",
    "    [0.5, 2.5, 0.3, 0.1],\n",
    "    [1.2, 0.2, 2.0, 0.5]\n",
    "])\n",
    "\n",
    "labels_t = torch.tensor([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ad7b4f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.44939341449096365\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits):\n",
    "    exp = np.exp(logits)\n",
    "    return exp/np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "def categorical_cross_entropy(logits, labels, eps=1e-12):\n",
    "    probs = softmax(logits)\n",
    "    N = logits.shape[0] \n",
    "    loss = -np.log(probs[np.arange(N), labels]+eps)\n",
    "    return np.mean(loss)\n",
    "\n",
    "ce = categorical_cross_entropy(logits_np, labels_np)\n",
    "print(\"CE Loss:\", ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d0c39832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: tensor(0.4494)\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits):\n",
    "    exp = torch.exp(logits)\n",
    "    return exp/torch.sum(exp, dim=1, keepdims=True)\n",
    "\n",
    "def categorical_cross_entropy(logits, labels, eps=1e-12):\n",
    "    probs = softmax(logits)\n",
    "    N = logits.shape[0]\n",
    "    loss = -torch.log(probs[torch.arange(N), labels]+eps)\n",
    "    return loss.mean()\n",
    "\n",
    "ce = categorical_cross_entropy(logits_t, labels_t)\n",
    "print(\"CE Loss:\", ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3079a1b",
   "metadata": {},
   "source": [
    "## Ranking Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3659d",
   "metadata": {},
   "source": [
    "### 1. Pointwise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d1bb7",
   "metadata": {},
   "source": [
    "#### 1.1. MSE (same as the regression loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda8d0c",
   "metadata": {},
   "source": [
    "#### 1.2. MAE (same as the regression loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c8175",
   "metadata": {},
   "source": [
    "#### 1.3 Binary Cross Entropy (same as the classifaction loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfdbda",
   "metadata": {},
   "source": [
    "### 2. Pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b509a7",
   "metadata": {},
   "source": [
    "#### 2.1 Hinge Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d6db1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_np = np.array([3.0, 2.5, 1.2])\n",
    "neg_np = np.array([1.0, 2.0, 1.0])\n",
    "\n",
    "pos_t = torch.tensor([3.0, 2.5, 1.2])\n",
    "neg_t = torch.tensor([1.0, 2.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2afa3d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss: 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "def hinge_loss(pos, neg, margin=1.0):\n",
    "    return np.mean(np.maximum(0, margin-(pos-neg)))\n",
    "\n",
    "hinge_loss = hinge_loss(pos_np, neg_np)\n",
    "print(\"Hinge Loss:\", hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "88ee9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss: tensor(0.4333)\n"
     ]
    }
   ],
   "source": [
    "def hinge_loss(pos, neg, margin=1.0):\n",
    "    return torch.mean(torch.clamp(margin-(pos-neg), min=0))\n",
    "\n",
    "hinge_loss = hinge_loss(pos_t, neg_t)\n",
    "print(\"Hinge Loss:\", hinge_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f6144e",
   "metadata": {},
   "source": [
    "#### 2.2 Logistic Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7bc4d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Loss: 0.3997146215348904\n"
     ]
    }
   ],
   "source": [
    "def logistic_loss(pos, neg):\n",
    "    return np.mean(np.log(1+np.exp(-(pos-neg))))\n",
    "\n",
    "logistic_loss = logistic_loss(pos_np, neg_np)\n",
    "print(\"Logistic Loss:\", logistic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "74e5dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Loss: tensor(0.3997)\n"
     ]
    }
   ],
   "source": [
    "def logistic_loss(pos, neg):\n",
    "    return torch.mean(torch.log(1+torch.exp(-(pos-neg))))\n",
    "logistic_loss = logistic_loss(pos_t, neg_t)\n",
    "print(\"Logistic Loss:\", logistic_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386705ba",
   "metadata": {},
   "source": [
    "#### 2.3 BPR Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "64bcef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR Loss: 0.3997146215348904\n"
     ]
    }
   ],
   "source": [
    "def bpr_loss(pos, neg):\n",
    "    return -np.mean(np.log(1/(1+np.exp(-(pos-neg)))))\n",
    "bpr_loss = bpr_loss(pos_np, neg_np)\n",
    "print(\"BPR Loss:\", bpr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d58ebd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR Loss: tensor(0.3997)\n"
     ]
    }
   ],
   "source": [
    "def bpr_loss(pos, neg):\n",
    "    return -torch.mean(torch.log(1/(1+torch.exp(-(pos-neg)))))\n",
    "bpr_loss = bpr_loss(pos_t, neg_t)\n",
    "print(\"BPR Loss:\", bpr_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10088eee",
   "metadata": {},
   "source": [
    "#### 2.4 Margin Ranking Loss (SVM Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "78bbba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin Ranking Loss: 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "def margin_ranking_loss(pos, neg, y, margin=1):\n",
    "    return np.mean(np.maximum(0, margin-y*(pos-neg)))\n",
    "\n",
    "margin_ranking_loss = margin_ranking_loss(pos_np, neg_np, y=1, margin=1)\n",
    "print(\"Margin Ranking Loss:\", margin_ranking_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6c394695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin Ranking Loss: tensor(0.4333)\n"
     ]
    }
   ],
   "source": [
    "def margin_ranking_loss(pos, neg, y, margin=1):\n",
    "    return torch.mean(torch.clamp(margin-y*(pos-neg), min=0))\n",
    "\n",
    "margin_ranking_loss = margin_ranking_loss(pos_t, neg_t, y=1, margin=1)\n",
    "print(\"Margin Ranking Loss:\", margin_ranking_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11980449",
   "metadata": {},
   "source": [
    "### 3. Listwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e43d3d",
   "metadata": {},
   "source": [
    "#### 3.1 ListNet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1020c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np = np.array([2.1, 1.0, 0.5, -0.2, 1.5])\n",
    "true_np = np.array([3.0, 2.0, 1.0, 0.0, 2.0])\n",
    "\n",
    "pred_t = torch.tensor([2.1, 1.0, 0.5, -0.2, 1.5])\n",
    "true_t = torch.tensor([3.0, 2.0, 1.0, 0.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "448fcefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listnet Loss: 1.2790021343290645\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    exp = np.exp(x)\n",
    "    return exp/np.sum(exp)\n",
    "\n",
    "def listnet_loss(pred_scores, true_scores):\n",
    "    P_true = softmax(true_scores)\n",
    "    P_pred = softmax(pred_scores)\n",
    "    loss = -np.sum(P_true*np.log(P_pred))\n",
    "    return loss\n",
    "\n",
    "listnet_loss = listnet_loss(pred_np, true_np)\n",
    "print(\"Listnet Loss:\", listnet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2029c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listnet Loss: tensor(1.2790)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jc/x24_p3ld3_55cc4d81vd3x0h0000gn/T/ipykernel_44690/913280877.py:8: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  loss = -torch.sum(P_true*np.log(P_pred))\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    exp = torch.exp(x)\n",
    "    return exp/torch.sum(exp)\n",
    "\n",
    "def listnet_loss(pred_scores, true_scores):\n",
    "    P_true = softmax(true_scores)\n",
    "    P_pred = softmax(pred_scores)\n",
    "    loss = -torch.sum(P_true*np.log(P_pred))\n",
    "    return loss\n",
    "\n",
    "listnet_loss = listnet_loss(pred_t, true_t)\n",
    "print(\"Listnet Loss:\", listnet_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3adff",
   "metadata": {},
   "source": [
    "#### 3.2 InfoNCE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6b986636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: [[-0.70834323 -1.43688441 -1.95069156  1.69155427  0.83022497  0.41467171\n",
      "   0.90003164  0.71840541]\n",
      " [ 0.07494945 -0.00951139 -0.85909234 -1.54578104 -0.13860638 -1.40494792\n",
      "  -1.08105348 -1.11175955]\n",
      " [-1.1548614   0.852863   -0.67854815  0.01383249 -1.29700878  1.84277265\n",
      "  -0.98883151 -0.3330663 ]\n",
      " [-0.25418583 -1.26277186  1.26739175 -0.88663619 -0.04162381  1.66623129\n",
      "   0.13419099 -1.53298745]]\n",
      "Key: [[-1.1658711  -1.59747827  0.13002691  0.16656563 -0.29080775  0.68623307\n",
      "   0.55509394 -1.01824037]\n",
      " [ 1.14979626  0.32240163 -1.32089382 -1.4061373  -0.66141214 -0.43399513\n",
      "  -0.06035458  0.16194982]\n",
      " [-0.7389324   2.15157486 -1.66363523 -0.08159468 -0.62202395  0.02009376\n",
      "  -0.14919493 -0.1887624 ]\n",
      " [ 0.27590294 -0.66227243 -1.36478619 -0.13411698  0.09396432 -0.33804415\n",
      "   1.43749694 -0.91166615]]\n"
     ]
    }
   ],
   "source": [
    "q_np = np.random.randn(4, 8)\n",
    "k_np = np.random.randn(4, 8)\n",
    "\n",
    "print(\"Query:\", q_np)\n",
    "print(\"Key:\", k_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b238a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: tensor([[-1.4569,  1.6060,  0.7825, -0.8799,  1.1309,  2.0260, -0.5535, -0.2143],\n",
      "        [-0.3234,  0.9806,  0.0604, -1.1901,  1.6995,  1.1238, -0.8171,  0.6541],\n",
      "        [ 1.2541, -0.1434,  0.9729, -1.0916,  0.5634,  0.6972, -0.0422, -1.4592],\n",
      "        [-1.3636, -1.8282,  1.1501, -1.0705,  1.2855,  0.1473,  0.6627,  0.3934]])\n",
      "Key: tensor([[-0.1116,  0.0834, -0.2129, -0.3214, -1.2527,  0.3528, -0.7192, -0.8067],\n",
      "        [-0.2126, -0.2815,  1.0260, -0.7254, -0.9999, -0.1493,  0.4120,  0.1061],\n",
      "        [-0.1742,  1.4896,  0.7534, -0.8012, -1.2617, -0.3526, -0.0418,  0.6707],\n",
      "        [-0.9145, -1.3882,  0.2915, -1.5326, -1.3399,  0.5254, -1.4797,  0.7023]])\n"
     ]
    }
   ],
   "source": [
    "q_t = torch.randn(4, 8)\n",
    "k_t = torch.randn(4, 8)\n",
    "\n",
    "print(\"Query:\", q_t)\n",
    "print(\"Key:\", k_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "db4135d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE: 20.538288848477517\n"
     ]
    }
   ],
   "source": [
    "def info_nce_loss(query, key, temperature=0.07):\n",
    "    \"\"\"\n",
    "    query: (N, D)\n",
    "    key: (N, D)\n",
    "    \"\"\"\n",
    "    logits = query@key.T/temperature\n",
    "    exp = np.exp(logits)\n",
    "    probs = exp/np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "    loss = -np.log(np.diag(probs))\n",
    "    return np.mean(loss)\n",
    "\n",
    "info_nce_loss = info_nce_loss(q_np, k_np)\n",
    "print(\"InfoNCE:\", info_nce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "565a599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE: tensor(18.2527)\n"
     ]
    }
   ],
   "source": [
    "def info_nce_loss(query, key, temperature=0.07):\n",
    "    logits = query@key.T/temperature\n",
    "\n",
    "    exp = torch.exp(logits)\n",
    "    probs = exp/torch.sum(exp, dim=1, keepdim=True)\n",
    "    loss = -torch.log(torch.diag(probs))\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "info_nce_loss = info_nce_loss(q_t, k_t)\n",
    "print(\"InfoNCE:\", info_nce_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prod_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
