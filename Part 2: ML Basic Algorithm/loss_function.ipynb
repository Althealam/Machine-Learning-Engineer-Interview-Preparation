{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b652257a",
   "metadata": {},
   "source": [
    "## Regression Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd1fe7",
   "metadata": {},
   "source": [
    "### 1. MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82c36065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true_np = np.array([3.0, 5.0, 2.5])\n",
    "y_pred_np = np.array([2.5, 5.5, 2.0])\n",
    "\n",
    "def mse_loss(pred, target):\n",
    "    return np.mean((pred-target)**2)\n",
    "mse = mse_loss(y_pred_np, y_true_np)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87f2027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: tensor(0.2500, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "y_true_t = torch.tensor([3.0, 5.0, 2.5])\n",
    "y_pred_t = torch.tensor([2.5, 5.5, 2.0], requires_grad=True)\n",
    "# requires_grad: 这个tensor参与梯度计算，需要在反向传播的时候计算他的梯度\n",
    "\n",
    "def mse_loss(pred, target):\n",
    "    return torch.mean((pred-target)**2)\n",
    "mse = mse_loss(y_pred_t, y_true_t)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faea552",
   "metadata": {},
   "source": [
    "### 2. MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9bdf0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5\n"
     ]
    }
   ],
   "source": [
    "def mae_loss(pred, target):\n",
    "    return np.mean(np.abs(pred-target))\n",
    "\n",
    "mae = mae_loss(y_pred_np, y_true_np)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27af240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: tensor(0.5000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def mae_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred-target))\n",
    "\n",
    "mae = mae_loss(y_pred_t, y_true_t)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422c907",
   "metadata": {},
   "source": [
    "### 3. Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ed1130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huber loss: 0.125\n"
     ]
    }
   ],
   "source": [
    "def huber_loss(pred, target, delta=1.0):\n",
    "    diff = np.abs(pred-target)\n",
    "    loss = np.where(\n",
    "        diff<=delta, \n",
    "        0.5*diff**2, \n",
    "        delta*(diff-0.5*delta)\n",
    "    )\n",
    "    return np.mean(loss)\n",
    "huber_loss = huber_loss(y_pred_np, y_true_np)\n",
    "print(\"huber loss:\", huber_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f993384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huber loss: tensor(0.1250, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def huber_loss(pred, target, delta=1.0):\n",
    "    diff = torch.abs(pred-target)\n",
    "    loss = torch.where(\n",
    "        diff<=delta, \n",
    "        0.5*diff**2, \n",
    "        delta*(diff-0.5*delta)\n",
    "    )\n",
    "    return loss.mean()\n",
    "huber_loss = huber_loss(y_pred_t, y_true_t)\n",
    "print(\"huber loss:\", huber_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0d0a7",
   "metadata": {},
   "source": [
    "### 4. RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f2f7088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5\n"
     ]
    }
   ],
   "source": [
    "def rmse_loss(pred, target):\n",
    "    return np.sqrt(np.mean((pred-target)**2))\n",
    "rmse = rmse_loss(y_pred_np, y_true_np)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a2f5a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: tensor(0.5000, grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def rmse_loss(pred, target):\n",
    "    return torch.sqrt(torch.mean((pred-target)**2))\n",
    "rmse = rmse_loss(y_pred_t, y_true_t)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa6e3f",
   "metadata": {},
   "source": [
    "## Classification Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fb646",
   "metadata": {},
   "source": [
    "### 1. Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6bd32239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y_true_np = np.array([1, 0, 1])\n",
    "y_true_t = torch.tensor([1., 0., 1.])\n",
    "\n",
    "# logits\n",
    "logits_np = np.array([0.2, 0.6, 0.2])\n",
    "logits_t = torch.tensor([0.2, 0.6, 0.2], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f71cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE Loss: 1.3779722793012823\n"
     ]
    }
   ],
   "source": [
    "def bce_loss(pred, target, eps=1e-4):\n",
    "    return -np.mean(target*np.log(pred+eps)+(1-target)*np.log(1-pred+eps))\n",
    "\n",
    "bce_loss = bce_loss(logits_np, y_true_np)\n",
    "print(\"BCE Loss:\", bce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69d8f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE Loss: tensor(-1.3780, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def bce_loss(pred, target, eps=1e-4):\n",
    "    return torch.mean(target*torch.log(pred+eps)+(1-target)*torch.log(1-pred+eps))\n",
    "bce_loss = bce_loss(logits_t, y_true_t)\n",
    "print(\"BCE Loss:\", bce_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47acd18f",
   "metadata": {},
   "source": [
    "### 2. Categorical Cross-Entropy (multiclass, but have only one label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4bd20516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch=3, classes=4\n",
    "logits_np = np.array([\n",
    "    [2.0, 1.0, 0.1, -1.0],  # batch 1\n",
    "    [0.5, 2.5, 0.3, 0.1], # batch 2\n",
    "    [1.2, 0.2, 2.0, 0.5] # batch 3\n",
    "])\n",
    "\n",
    "labels_np = np.array([0, 1, 2])\n",
    "\n",
    "logits_t = torch.tensor([\n",
    "    [2.0, 1.0, 0.1, -1.0],\n",
    "    [0.5, 2.5, 0.3, 0.1],\n",
    "    [1.2, 0.2, 2.0, 0.5]\n",
    "])\n",
    "\n",
    "labels_t = torch.tensor([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ad7b4f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.44939341449096365\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits):\n",
    "    exp = np.exp(logits)\n",
    "    return exp/np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "def categorical_cross_entropy(logits, labels, eps=1e-12):\n",
    "    probs = softmax(logits)\n",
    "    N = logits.shape[0] \n",
    "    loss = -np.log(probs[np.arange(N), labels]+eps)\n",
    "    return np.mean(loss)\n",
    "\n",
    "ce = categorical_cross_entropy(logits_np, labels_np)\n",
    "print(\"CE Loss:\", ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d0c39832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: tensor(0.4494)\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits):\n",
    "    exp = torch.exp(logits)\n",
    "    return exp/torch.sum(exp, dim=1, keepdims=True)\n",
    "\n",
    "def categorical_cross_entropy(logits, labels, eps=1e-12):\n",
    "    probs = softmax(logits)\n",
    "    N = logits.shape[0]\n",
    "    loss = -torch.log(probs[torch.arange(N), labels]+eps)\n",
    "    return loss.mean()\n",
    "\n",
    "ce = categorical_cross_entropy(logits_t, labels_t)\n",
    "print(\"CE Loss:\", ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3079a1b",
   "metadata": {},
   "source": [
    "## Ranking Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3659d",
   "metadata": {},
   "source": [
    "### 1. Pointwise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d1bb7",
   "metadata": {},
   "source": [
    "#### 1.1. MSE (same as the regression loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda8d0c",
   "metadata": {},
   "source": [
    "#### 1.2. MAE (same as the regression loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c8175",
   "metadata": {},
   "source": [
    "#### 1.3 Binary Cross Entropy (same as the classifaction loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfdbda",
   "metadata": {},
   "source": [
    "### 2. Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa3d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prod_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
